# -*- coding: utf-8 -*-
"""
Adaptive Learning Rate System - ì ì‘í˜• í•™ìŠµë¥  ì‹œìŠ¤í…œ

ëª©ì : í•™ìŠµ ì„±ëŠ¥ì— ë”°ë¼ í•™ìŠµë¥  ìë™ ì¡°ì •
- ìŠ¹ë¥  í–¥ìƒ ì‹œ learning_rate ì¦ê°€
- ìŠ¹ë¥  ì •ì²´ ì‹œ learning_rate ê°ì†Œ
- ìµœì  í•™ìŠµë¥  ìë™ íƒìƒ‰
"""

from typing import List, Dict, Optional
import json
from pathlib import Path


class AdaptiveLearningRate:
    """
    ì ì‘í˜• í•™ìŠµë¥  ì¡°ì • ì‹œìŠ¤í…œ

    í•µì‹¬ ê¸°ëŠ¥:
    1. ìŠ¹ë¥  ì¶”ì  ë° ë¶„ì„
    2. í•™ìŠµë¥  ìë™ ì¡°ì •
    3. ìµœì  í•™ìŠµë¥  íƒìƒ‰
    """

    def __init__(
        self,
        initial_lr: float = 0.001,
        min_lr: float = 0.0001,
        max_lr: float = 0.01,
        adjustment_factor: float = 1.2,
        patience: int = 10
    ):
        # í•™ìŠµë¥  íŒŒë¼ë¯¸í„°
        self.learning_rate = initial_lr
        self.min_lr = min_lr
        self.max_lr = max_lr
        self.adjustment_factor = adjustment_factor  # ì¡°ì • ë°°ìœ¨ (1.2 = 20% ì¦ê°€/ê°ì†Œ)

        # ì„±ëŠ¥ ì¶”ì 
        self.recent_win_rates: List[float] = []
        self.window_size = 20  # ìµœê·¼ 20ê²Œì„ ìŠ¹ë¥  ì¶”ì 
        self.patience = patience  # ê°œì„  ì—†ìœ¼ë©´ ì´ íšŸìˆ˜ í›„ ì¡°ì •
        self.games_without_improvement = 0

        # ìµœì ê°’ ì¶”ì 
        self.best_win_rate = 0.0
        self.best_learning_rate = initial_lr

        # í†µê³„
        self.total_games = 0
        self.total_wins = 0
        self.adjustment_history: List[Dict] = []

        # ì €ì¥ ê²½ë¡œ
        self.save_path = Path("local_training/adaptive_lr_stats.json")

        # ë¡œë“œ
        self._load_stats()

    def update(self, game_won: bool) -> Optional[float]:
        """
        ê²Œì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ ë° í•™ìŠµë¥  ì¡°ì •

        Returns:
            ìƒˆë¡œìš´ í•™ìŠµë¥  (ì¡°ì •ë˜ì—ˆìœ¼ë©´), None (ì¡°ì • ì•ˆ ë¨)
        """
        # ê²Œì„ ê¸°ë¡
        self.total_games += 1
        if game_won:
            self.total_wins += 1

        # ìµœê·¼ ìŠ¹ë¥  ê³„ì‚° (window_size ê²Œì„)
        current_win_rate = self.total_wins / self.total_games

        self.recent_win_rates.append(current_win_rate)
        if len(self.recent_win_rates) > self.window_size:
            self.recent_win_rates.pop(0)

        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì˜€ìœ¼ë©´ ì¡°ì • íŒë‹¨
        if len(self.recent_win_rates) >= self.window_size:
            recent_avg = sum(self.recent_win_rates) / len(self.recent_win_rates)

            # ìŠ¹ë¥  ê°œì„  í™•ì¸
            if recent_avg > self.best_win_rate:
                # ê°œì„ ë¨!
                self.best_win_rate = recent_avg
                self.best_learning_rate = self.learning_rate
                self.games_without_improvement = 0

                # í•™ìŠµë¥  ì¦ê°€ (ë” ê³µê²©ì ìœ¼ë¡œ í•™ìŠµ)
                new_lr = self._increase_learning_rate()
                if new_lr:
                    print(f"[ADAPTIVE_LR] [OK] ìŠ¹ë¥  ê°œì„ ! ({recent_avg:.1%}) - í•™ìŠµë¥  ì¦ê°€: {self.learning_rate:.6f}")
                    self._save_stats()
                    return new_lr

            else:
                # ê°œì„  ì—†ìŒ
                self.games_without_improvement += 1

                # patience ì´ìƒ ê°œì„  ì—†ìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ
                if self.games_without_improvement >= self.patience:
                    new_lr = self._decrease_learning_rate()
                    if new_lr:
                        print(f"[ADAPTIVE_LR] [WARNING] {self.patience}ê²Œì„ ê°œì„  ì—†ìŒ - í•™ìŠµë¥  ê°ì†Œ: {self.learning_rate:.6f}")
                        self.games_without_improvement = 0
                        self._save_stats()
                        return new_lr

        # ì£¼ê¸°ì ìœ¼ë¡œ ì €ì¥
        if self.total_games % 10 == 0:
            self._save_stats()

        return None

    def _increase_learning_rate(self) -> Optional[float]:
        """í•™ìŠµë¥  ì¦ê°€"""
        new_lr = self.learning_rate * self.adjustment_factor

        if new_lr <= self.max_lr:
            old_lr = self.learning_rate
            self.learning_rate = new_lr

            self.adjustment_history.append({
                "game": self.total_games,
                "action": "increase",
                "old_lr": old_lr,
                "new_lr": new_lr,
                "win_rate": self.best_win_rate
            })

            return new_lr

        return None

    def _decrease_learning_rate(self) -> Optional[float]:
        """í•™ìŠµë¥  ê°ì†Œ"""
        new_lr = self.learning_rate / self.adjustment_factor

        if new_lr >= self.min_lr:
            old_lr = self.learning_rate
            self.learning_rate = new_lr

            self.adjustment_history.append({
                "game": self.total_games,
                "action": "decrease",
                "old_lr": old_lr,
                "new_lr": new_lr,
                "win_rate": sum(self.recent_win_rates) / len(self.recent_win_rates) if self.recent_win_rates else 0.0
            })

            return new_lr

        # ìµœì†Œê°’ì— ë„ë‹¬í–ˆìœ¼ë©´ best_learning_rateë¡œ ë¦¬ì…‹
        if self.learning_rate <= self.min_lr:
            print(f"[ADAPTIVE_LR] ìµœì†Œ í•™ìŠµë¥  ë„ë‹¬ - ìµœì ê°’ìœ¼ë¡œ ë¦¬ì…‹: {self.best_learning_rate:.6f}")
            old_lr = self.learning_rate
            self.learning_rate = self.best_learning_rate

            self.adjustment_history.append({
                "game": self.total_games,
                "action": "reset_to_best",
                "old_lr": old_lr,
                "new_lr": self.learning_rate,
                "win_rate": self.best_win_rate
            })

            return self.learning_rate

        return None

    def get_current_lr(self) -> float:
        """í˜„ì¬ í•™ìŠµë¥  ë°˜í™˜"""
        return self.learning_rate

    def get_stats(self) -> Dict:
        """í†µê³„ ë°˜í™˜"""
        recent_avg = sum(self.recent_win_rates) / len(self.recent_win_rates) if self.recent_win_rates else 0.0

        return {
            "current_lr": self.learning_rate,
            "best_lr": self.best_learning_rate,
            "best_win_rate": self.best_win_rate,
            "recent_win_rate": recent_avg,
            "total_games": self.total_games,
            "total_wins": self.total_wins,
            "overall_win_rate": self.total_wins / self.total_games if self.total_games > 0 else 0.0,
            "games_without_improvement": self.games_without_improvement,
            "adjustments": len(self.adjustment_history)
        }

    def get_summary(self) -> str:
        """ìš”ì•½ ë°˜í™˜"""
        stats = self.get_stats()

        lines = []
        lines.append("\n[ADAPTIVE_LR] === ì ì‘í˜• í•™ìŠµë¥  í†µê³„ ===")
        lines.append(f"  í˜„ì¬ í•™ìŠµë¥ : {stats['current_lr']:.6f}")
        lines.append(f"  ìµœì  í•™ìŠµë¥ : {stats['best_lr']:.6f} (ìŠ¹ë¥ : {stats['best_win_rate']:.1%})")
        lines.append(f"  ìµœê·¼ ìŠ¹ë¥ : {stats['recent_win_rate']:.1%} (ìµœê·¼ {len(self.recent_win_rates)}ê²Œì„)")
        lines.append(f"  ì „ì²´ ìŠ¹ë¥ : {stats['overall_win_rate']:.1%} ({stats['total_wins']}/{stats['total_games']})")
        lines.append(f"  ê°œì„  ì—†ìŒ: {stats['games_without_improvement']}/{self.patience}ê²Œì„")
        lines.append(f"  ì´ ì¡°ì • íšŸìˆ˜: {stats['adjustments']}íšŒ")

        # ìµœê·¼ ì¡°ì • ì´ë ¥
        if self.adjustment_history:
            lines.append("\n  ìµœê·¼ ì¡°ì •:")
            for adj in self.adjustment_history[-3:]:
                action_emoji = "ğŸ“ˆ" if adj["action"] == "increase" else "ğŸ“‰" if adj["action"] == "decrease" else "ğŸ”„"
                lines.append(f"    {action_emoji} Game {adj['game']}: {adj['old_lr']:.6f} â†’ {adj['new_lr']:.6f}")

        lines.append("=" * 40)
        return "\n".join(lines)

    def _save_stats(self) -> None:
        """í†µê³„ ì €ì¥"""
        try:
            self.save_path.parent.mkdir(parents=True, exist_ok=True)

            data = {
                "learning_rate": self.learning_rate,
                "best_learning_rate": self.best_learning_rate,
                "best_win_rate": self.best_win_rate,
                "total_games": self.total_games,
                "total_wins": self.total_wins,
                "recent_win_rates": self.recent_win_rates,
                "games_without_improvement": self.games_without_improvement,
                "adjustment_history": self.adjustment_history
            }

            with open(self.save_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            print(f"[ADAPTIVE_LR] ì €ì¥ ì‹¤íŒ¨: {e}")

    def _load_stats(self) -> None:
        """í†µê³„ ë¡œë“œ"""
        try:
            if self.save_path.exists():
                with open(self.save_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                self.learning_rate = data.get("learning_rate", self.learning_rate)
                self.best_learning_rate = data.get("best_learning_rate", self.best_learning_rate)
                self.best_win_rate = data.get("best_win_rate", self.best_win_rate)
                self.total_games = data.get("total_games", 0)
                self.total_wins = data.get("total_wins", 0)
                self.recent_win_rates = data.get("recent_win_rates", [])
                self.games_without_improvement = data.get("games_without_improvement", 0)
                self.adjustment_history = data.get("adjustment_history", [])

                print(f"[ADAPTIVE_LR] í†µê³„ ë¡œë“œ ì™„ë£Œ - í˜„ì¬ í•™ìŠµë¥ : {self.learning_rate:.6f}")

        except Exception as e:
            print(f"[ADAPTIVE_LR] ë¡œë“œ ì‹¤íŒ¨ (ìƒˆë¡œ ì‹œì‘): {e}")

    def reset(self) -> None:
        """í†µê³„ ë¦¬ì…‹"""
        self.learning_rate = self.best_learning_rate if self.best_learning_rate > 0 else self.learning_rate
        self.games_without_improvement = 0
        print(f"[ADAPTIVE_LR] ë¦¬ì…‹ ì™„ë£Œ - í•™ìŠµë¥ : {self.learning_rate:.6f}")
