# ì¶©ëŒ í•´ê²° ë° í•™ìŠµ ë°ì´í„° í˜„í™© ë³´ê³ ì„œ

## 1. ì¶©ëŒ í•´ê²° ìƒíƒœ (Conflict Resolution Status)

### âœ… í•´ê²° ì™„ë£Œ: Import Conflict
**íŒŒì¼:** `run_with_training.py` (Line 624)
```python
# BEFORE:
if game_count > 0:
    from tools.extract_and_train_from_training import TrainingDataExtractor

# AFTER:
if False and game_count > 0:  # Disabled - module doesn't exist
```
**ê²°ê³¼:** ê²Œì„ ì¢…ë£Œ ì‹œ í¬ë˜ì‹œ ë¬¸ì œ í•´ê²°ë¨

---

### âš ï¸ ë¶€ë¶„ í•´ê²°: Resource Management Conflict
**ëŒ€ìƒ:** ProductionResilience vs EconomyManager

**í˜„ì¬ ìƒíƒœ:**
- ë‘ ë§¤ë‹ˆì € ëª¨ë‘ í™œì„±í™”ë¨ (wicked_zerg_bot_pro_impl.py:79-92)
- ProductionResilience: ì•ˆì „í•œ ìœ ë‹› ìƒì‚° (retry logic)
- EconomyManager: ìì› ìˆ˜ì§‘, í™•ì¥, ì¼ê¾¼ ìƒì‚°

**ì¶©ëŒ ê°€ëŠ¥ì„±:**
- ë‘ ë§¤ë‹ˆì €ê°€ ë™ì‹œì— ì¼ê¾¼ ìƒì‚°ì„ ì‹œë„í•  ìˆ˜ ìˆìŒ
- ë¯¸ë„¤ë„/ê°€ìŠ¤ ë¶€ì¡± ì‹œ ìš°ì„ ìˆœìœ„ ë¶ˆëª…í™•

**ê¶Œì¥ í•´ê²°ì±…:**
```python
# bot_step_integration.pyì—ì„œ ëª…í™•í•œ ì‹¤í–‰ ìˆœì„œ ì •ì˜
1. EconomyManager ë¨¼ì € ì‹¤í–‰ (ìì› í™•ë³´)
2. ProductionResilienceëŠ” EconomyManagerì˜ ê²°ì • í›„ ì‹¤í–‰
   - ë˜ëŠ” ProductionResilienceë¥¼ ìœ ë‹› ìƒì‚° ì „ìš©ìœ¼ë¡œ ì œí•œ
   - EconomyManagerëŠ” ì¼ê¾¼ ìƒì‚°ë§Œ ë‹´ë‹¹
```

**í˜„ì¬ ì‹¤í–‰ ìˆœì„œ (bot_step_integration.py):**
- Line 138: EconomyManager (5ë¶„ ì´ë‚´)
- ProductionResilienceëŠ” ëª…ì‹œì  í˜¸ì¶œì´ ì—†ìŒ (ë‹¤ë¥¸ ë§¤ë‹ˆì €ë“¤ì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©)

**ë¶„ì„:** ì‹¤ì œë¡œëŠ” í° ì¶©ëŒ ì—†ìŒ. ProductionResilienceëŠ” ë‹¤ë¥¸ ë§¤ë‹ˆì €ë“¤ì˜ í—¬í¼ í´ë˜ìŠ¤ë¡œ ì‚¬ìš©ë¨.

---

### âŒ ë¯¸í•´ê²°: Control Conflict (ê°€ì¥ ì¤‘ìš”!)
**ëŒ€ìƒ:** RLAgent vs AggressiveStrategyExecutor

**í˜„ì¬ ìƒíƒœ:**
- **RLAgent** (bot_step_integration.py:697): ê²Œì„ ì „ë°˜ì  ì „ëµ ê²°ì • (ê³µê²©/ë°©ì–´/í™•ì¥)
- **AggressiveStrategyExecutor** (aggressive_strategies.py:48): ì´ˆë°˜ ëŸ¬ì‹œ ì „ëµ ì‹¤í–‰ (12í’€, ë§¹ë…ì¶© ì˜¬ì¸ ë“±)

**ì¶©ëŒ ì‹œë‚˜ë¦¬ì˜¤:**
```
ì‹œê°„: 2ë¶„ 30ì´ˆ
RLAgent ê²°ì •: "DEFEND" (ë°©ì–´)
AggressiveStrategy: "12 POOL RUSH" ì§„í–‰ ì¤‘ â†’ ì €ê¸€ë§ 6ë§ˆë¦¬ ì ì§„ ëŒê²© ì¤‘

ê²°ê³¼: ìœ ë‹›ë“¤ì´ ì™”ë‹¤ê°”ë‹¤ (Oscillation)
```

**ê¶Œì¥ í•´ê²°ì±… (ê³„ì¸µì  êµ¬ì¡°):**
```python
# bot_step_integration.pyì— ì¶”ê°€

if self.bot.time < 300.0:  # ì´ˆë°˜ 5ë¶„
    # AggressiveStrategyê°€ ì „ê¶Œ
    use_aggressive_strategy = True
    use_rl_decision = False
else:
    # 5ë¶„ ì´í›„ RLAgentê°€ ì§€íœ˜ê¶Œ ë„˜ê²¨ë°›ìŒ
    use_aggressive_strategy = False
    use_rl_decision = True

# íŠ¹ìˆ˜ ìƒí™©: RLì´ ëª…ì‹œì ìœ¼ë¡œ "RUSH" ì„ íƒ ì‹œ AggressiveStrategy ì¬í™œì„±í™”
if rl_decision_label in ["ATTACK", "ALL_IN"]:
    use_aggressive_strategy = True
```

**í˜„ì¬ ì½”ë“œ ë¬¸ì œ:**
- Line 697: RLAgentê°€ í•­ìƒ ê²°ì •í•¨
- AggressiveStrategy ì‹¤í–‰ ì—¬ë¶€ë¥¼ RLAgent ê²°ì •ê³¼ ì¡°ìœ¨í•˜ëŠ” ë¡œì§ ì—†ìŒ

---

## 2. í•™ìŠµ ë°ì´í„° í˜„í™© (Training Data Status)

### ğŸ“Š í˜„ì¬ RLAgent í•™ìŠµ ìƒíƒœ
```json
{
  "curriculum_level": 0,
  "games_played": 6,
  "wins": 0,
  "losses": 5,
  "win_rate": 0.0,
  "epsilon": ~0.97 (ì•„ì§ ê±°ì˜ ëœë¤ íƒìƒ‰)
}
```

**ë¶„ì„:**
- âœ… Epsilon-Greedy ì‹œìŠ¤í…œ ì‘ë™ ì¤‘
- âœ… ê²½í—˜ ì €ì¥ ì‹œìŠ¤í…œ êµ¬í˜„ë¨ (rl_agent.py:267)
- âŒ ì‹¤ì œ ì €ì¥ëœ ê²½í—˜ ë°ì´í„°: **0ê°œ** (local_training/data/buffer/ ë¹„ì–´ìˆìŒ)
- âŒ í•™ìŠµì´ ê±°ì˜ ì•ˆ ë¨ (6ê²Œì„ë§Œ í”Œë ˆì´)

### ğŸ“ í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
local_training/data/
â”œâ”€â”€ buffer/          â† ê²½í—˜ ë°ì´í„° ì €ì¥ì†Œ (í˜„ì¬ ë¹„ì–´ìˆìŒ!)
â”œâ”€â”€ archive/         â† ê³¼ê±° ë°ì´í„° ë³´ê´€ (ë¹„ì–´ìˆìŒ)
â”œâ”€â”€ training_stats.json  â† ì»¤ë¦¬í˜ëŸ¼ ì§„í–‰ë„
â””â”€â”€ race_stats.json      â† ì¢…ì¡±ë³„ í†µê³„
```

**ë¬¸ì œì :**
1. RLAgent.end_episode()ì—ì„œ `save_experience=True`ë¡œ í˜¸ì¶œë˜ëŠ”ë° ì‹¤ì œ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•ŠìŒ
2. buffer/ ë””ë ‰í† ë¦¬ì— .npz íŒŒì¼ì´ ì—†ìŒ â†’ ë°°ê²½ í•™ìŠµ(Background Learning) ë¶ˆê°€ëŠ¥

---

## 3. ë¦¬í”Œë ˆì´ í•™ìŠµ ì‹œìŠ¤í…œ (Replay Learning)

### ğŸ¬ Replay Learning ê°œìš”
**íŒŒì¼:** `local_training/scripts/replay_build_order_learner.py`

**ê¸°ëŠ¥:**
1. SC2Replay íŒŒì¼ íŒŒì‹± (sc2reader ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
2. í”„ë¡œ ê²Œì´ë¨¸ ë¹Œë“œ ì˜¤ë” ì¶”ì¶œ
3. ì €ê·¸ ì „ëµ íŒ¨í„´ í•™ìŠµ
4. ì¢…ì¡±ë³„ ë¹Œë“œ ì˜¤ë” ë¶„ë¥˜ (vs Terran/Protoss/Zerg)

**í•™ìŠµ ëŒ€ìƒ:**
- ìœ ë‹› ìƒì‚° ìˆœì„œ
- ê±´ë¬¼ ê±´ì„¤ íƒ€ì´ë°
- ì—…ê·¸ë ˆì´ë“œ ìˆœì„œ
- ê²Œì„ ê¸¸ì´ë³„ ì „ëµ

**í•„ìš” ì¡°ê±´:**
```bash
pip install sc2reader
```

**ì‚¬ìš© ë°©ë²•:**
```bash
# ë¦¬í”Œë ˆì´ íŒŒì¼ì„ replays/ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
python -m wicked_zerg_challenger.local_training.scripts.replay_build_order_learner
```

**ì¶œë ¥:**
- `learned_build_orders.json`: ì¶”ì¶œëœ ë¹Œë“œ ì˜¤ë”
- ì¢…ì¡±ë³„ ìŠ¹ë¥  í†µê³„
- íƒ€ì´ë° ê³µê²© íŒ¨í„´

---

## 4. ë¹„êµ í•™ìŠµ ë°ì´í„° (Comparative Learning)

### ğŸ“ˆ ë¹„êµ í•™ìŠµì´ë€?
ìì‹ ì˜ ê³¼ê±° ê²Œì„ ë°ì´í„°ì™€ í”„ë¡œ ë¦¬í”Œë ˆì´ë¥¼ ë¹„êµí•˜ì—¬ ê°œì„ ì ì„ ì°¾ëŠ” í•™ìŠµ ë°©ì‹

**í˜„ì¬ êµ¬í˜„ëœ ë¹„êµ ì‹œìŠ¤í…œ:**

#### A. Session Comparison (run_with_training.py)
```python
SessionManager.get_training_summary()
```
- ì„¸ì…˜ ë‚´ ê²Œì„ë³„ ì„±ëŠ¥ ë¹„êµ
- ìŠ¹ë¥ , í‰ê·  ê²Œì„ ì‹œê°„, ìì› íš¨ìœ¨

#### B. Build Order Comparison (ë¯¸êµ¬í˜„ - íŒŒì¼ ì—†ìŒ)
```python
# tools/extract_and_train_from_training.py (missing!)
extract_build_order_comparisons()
```
ì˜ˆìƒ ê¸°ëŠ¥:
- ìŠ¹ë¦¬í•œ ê²Œì„ì˜ ë¹Œë“œ ì˜¤ë” vs íŒ¨ë°°í•œ ê²Œì„ ë¹„êµ
- íƒ€ì´ë° ì°¨ì´ ë¶„ì„
- ìœ ë‹› êµ¬ì„± ìµœì í™”

---

## 5. í˜„ì¬ êµ¬í˜„ëœ ë¹Œë“œ/ì „ëµ ëª©ë¡

### ê³µê²© ì „ëµ (AggressiveStrategyExecutor)
1. **12 Pool** - 12ë“œë¡  ì €ê¸€ë§ ëŸ¬ì‹œ
2. **Baneling Bust** - 13/12 ë§¹ë…ì¶© ì˜¬ì¸
3. **Ravager Rush** - ê¶¤ë©¸ì¶© ë‹´ì¦™ ëŸ¬ì‹œ
4. **Tunneling Claws** - ì ë³µ ë°”í€´ ì´ë™
5. **Proxy Hatchery** - ì „ì§„ í•´ì²˜ë¦¬
6. **Nydus All-In** - ë•…êµ´ë§ ì˜¬ì¸
7. **Overlord Drop** - ëŒ€êµ°ì£¼ ë“œë ê²¬ì œ

### ê²½ì œ ì „ëµ (EconomyManager)
- í™•ì¥ íƒ€ì´ë°
- ì¼ê¾¼ ìƒì‚° ë°¸ëŸ°ìŠ¤
- ê°€ìŠ¤ íƒ€ì´ë°

### ìœ ë‹› ìƒì‚° (ProductionResilience)
- ì•ˆì „í•œ ìœ ë‹› ìƒì‚° (retry logic)
- ì—ëŸ¬ ë³µêµ¬

---

## 6. RLAgent í•™ìŠµ ê³„íš

### Phase 1: ê¸°ì¡´ ì „ëµ ë°ì´í„° ìˆ˜ì§‘ (í˜„ì¬ ë‹¨ê³„)
**ëª©í‘œ:** ê° ì „ëµì„ ì¶©ë¶„íˆ ì‹¤í–‰í•˜ì—¬ ê²½í—˜ ë°ì´í„° ìˆ˜ì§‘

**í•„ìš” ì‘ì—…:**
```python
# ê° ì „ëµë‹¹ ìµœì†Œ 10ê²Œì„ì”© ì‹¤í–‰
strategies = [
    "12pool", "baneling_bust", "ravager_rush",
    "tunneling", "proxy_hatch", "nydus_allin", "overlord_drop"
]

# ì´ ê²Œì„ ìˆ˜: 7 ì „ëµ Ã— 10ê²Œì„ = 70ê²Œì„
# í˜„ì¬ ê²Œì„ ìˆ˜: 6ê²Œì„
# ë¶€ì¡± ê²Œì„ ìˆ˜: 64ê²Œì„
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
python -m wicked_zerg_challenger.run_with_training --num_games 70
```

### Phase 2: ê²½í—˜ ë°ì´í„° ê²€ì¦
```bash
# buffer/ ë””ë ‰í† ë¦¬ì— .npz íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
ls local_training/data/buffer/

# ì˜ˆìƒ íŒŒì¼: exp_20260125_143052_ep1.npz
```

### Phase 3: Background Learning í™œì„±í™”
```bash
# ë°°ê²½ í•™ìŠµ ì‹œì‘ (ê¸°ì¡´ ê²½í—˜ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµ)
python -m wicked_zerg_challenger.tools.background_parallel_learner
```

### Phase 4: Replay Learning í†µí•©
```bash
# 1. í”„ë¡œ ë¦¬í”Œë ˆì´ ë‹¤ìš´ë¡œë“œ
# 2. replays/ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
# 3. ë¦¬í”Œë ˆì´ í•™ìŠµ ì‹¤í–‰
python -m wicked_zerg_challenger.local_training.scripts.replay_build_order_learner
```

---

## 7. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…

### âœ… ìš°ì„ ìˆœìœ„ 1: Control Conflict í•´ê²°
```python
# bot_step_integration.pyì— ì‹œê°„ ê¸°ë°˜ ì „í™˜ ë¡œì§ ì¶”ê°€
# ì´ˆë°˜ 5ë¶„ = AggressiveStrategy ìš°ì„ 
# 5ë¶„ ì´í›„ = RLAgent ìš°ì„ 
```

### âœ… ìš°ì„ ìˆœìœ„ 2: ê²½í—˜ ë°ì´í„° ì €ì¥ í™•ì¸
```python
# rl_agent.pyì˜ save_experience_data() ë©”ì„œë“œê°€ ì‹¤ì œë¡œ íŒŒì¼ì„ ì €ì¥í•˜ëŠ”ì§€ í™•ì¸
# buffer/ ë””ë ‰í† ë¦¬ì— .npz íŒŒì¼ì´ ìƒì„±ë˜ëŠ”ì§€ ê²€ì¦
```

### âœ… ìš°ì„ ìˆœìœ„ 3: ëŒ€ëŸ‰ í•™ìŠµ ì‹¤í–‰
```bash
# 70ê²Œì„ ì—°ì† ì‹¤í–‰ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘
python -m wicked_zerg_challenger.run_with_training --num_games 70
```

---

## 8. ì¢…í•© ê¶Œì¥ ì‚¬í•­

1. **ì¦‰ì‹œ ì¡°ì¹˜:** Control Conflict í•´ê²° (5ë¶„ ì‹œê°„ ê¸°ë°˜ ì „í™˜)
2. **ë°ì´í„° ìˆ˜ì§‘:** 70ê²Œì„ ì‹¤í–‰ìœ¼ë¡œ ê° ì „ëµ ê²½í—˜ ë°ì´í„° í™•ë³´
3. **ê²€ì¦:** buffer/ ë””ë ‰í† ë¦¬ì— .npz íŒŒì¼ ìƒì„± í™•ì¸
4. **ë°°ê²½ í•™ìŠµ:** Background Learner í™œì„±í™”
5. **ì¥ê¸° ê³¼ì œ:** Replay Learning ì‹œìŠ¤í…œì— í”„ë¡œ ë¦¬í”Œë ˆì´ íˆ¬ì…

**ì˜ˆìƒ í•™ìŠµ ì‹œê°„:**
- ê²Œì„ë‹¹ í‰ê·  5ë¶„ (ë¹ ë¥¸ ëŸ¬ì‹œ ì „ëµ)
- 70ê²Œì„ Ã— 5ë¶„ = 350ë¶„ (ì•½ 6ì‹œê°„)
- Background Learning: ì¶”ê°€ 2-3ì‹œê°„
- **ì´ ì†Œìš” ì‹œê°„: ì•½ 8-9ì‹œê°„**

---

ìƒì„± ì‹œê°: 2026-01-25
