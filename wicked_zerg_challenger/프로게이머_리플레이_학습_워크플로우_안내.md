# 프로게이머 리플레이 학습 및 게임 훈련 적용 워크플로우

**생성 일시**: 2026-01-19

---

## ? 워크플로우 개요

이 워크플로우는 프로게이머의 리플레이를 학습하여 봇의 빌드오더를 개선하는 통합 시스템입니다.

### 주요 단계

1. **프로게이머 리플레이에서 빌드오더 학습**
   - `local_training/scripts/replay_build_order_learner.py` 실행
   - 프로게이머 리플레이에서 최적 빌드오더 타이밍 추출
   - 학습된 파라미터를 `learned_build_orders.json`에 저장

2. **학습된 빌드오더를 config.py에 적용**
   - `learned_build_orders.json`의 파라미터를 자동으로 `config.py`에 적용
   - `get_learned_parameter()` 함수를 통해 게임 중 사용

3. **게임 훈련 실행 (학습된 빌드오더 적용)**
   - `run_with_training.py` 실행
   - 학습된 빌드오더가 자동으로 적용되어 게임 실행
   - 봇의 리플레이 생성

4. **봇의 리플레이와 프로게이머 리플레이 비교 분석**
   - `local_training/strategy_audit.py` 실행
   - 시간 오차, 순서 오류, 자원 효율 분석
   - 비교 리포트 생성

5. **개선 사항 적용 및 반복**
   - 분석 결과를 바탕으로 다음 학습에 반영
   - 최대 5회 반복하여 지속적 개선

---

## ? 실행 방법

### 방법 1: Python 스크립트 직접 실행
```bash
cd D:\Swarm-contol-in-sc2bot\wicked_zerg_challenger
python tools\pro_replay_learning_workflow.py
```

### 방법 2: 배치 파일 실행
```bash
cd D:\Swarm-contol-in-sc2bot\wicked_zerg_challenger
bat\pro_replay_learning_workflow.bat
```

---

## ? 예상 소요 시간

- **리플레이 학습 1회**: 약 10-30분 (리플레이 수에 따라)
- **게임 훈련 1회**: 약 30-60분 (게임 수에 따라)
- **비교 분석 1회**: 약 10-30분 (리플레이 수에 따라)
- **총 5회 반복**: 약 250-600분 (4-10시간)

---

## ? 학습 프로세스

### 1단계: 프로게이머 리플레이 학습

```
프로게이머 리플레이 (D:\replays\replays)
    ↓
빌드오더 추출 (replay_build_order_learner.py)
    ↓
학습된 파라미터 (learned_build_orders.json)
    ↓
config.py 자동 적용
```

**학습되는 파라미터:**
- `spawning_pool_supply`: 스포닝 풀 건설 타이밍
- `gas_supply`: 가스 추출기 건설 타이밍
- `natural_expansion_supply`: 멀티 확장 타이밍
- `roach_warren_supply`: 로취 워런 건설 타이밍
- `hydralisk_den_supply`: 히드라리스크 덴 건설 타이밍
- 기타 빌드오더 타이밍

### 2단계: 게임 훈련 (학습된 빌드오더 적용)

```
게임 시작
    ↓
config.py에서 학습된 파라미터 로드
    ↓
프로게이머 빌드오더 기반으로 게임 실행
    ↓
봇의 리플레이 생성
```

### 3단계: 비교 분석

```
프로게이머 리플레이
    ↓
봇의 리플레이
    ↓
비교 분석 (strategy_audit.py)
    ↓
시간 오차, 순서 오류, 자원 효율 분석
    ↓
비교 리포트 생성
```

---

## ? 생성되는 파일

### 학습된 빌드오더
- **위치**: `local_training/scripts/learned_build_orders.json`
- **내용**: 프로게이머 리플레이에서 학습된 빌드오더 파라미터
- **자동 적용**: `config.py`의 `get_learned_parameter()` 함수를 통해 자동 적용

### 비교 리포트
- **위치**: `local_training/comparison_reports/`
- **파일**: `comparison_analysis_report.md`
- **내용**:
  - 시간 오차 분석 결과
  - 순서 오류 분석 결과
  - 자원 효율 분석 결과
  - 개선 권장사항

### 게임 통계
- **위치**: `local_training/scripts/training_session_stats.json`
- **내용**: 게임 결과 및 통계

---

## ?? 설정

### 리플레이 경로
- **기본 경로**: `D:\replays\replays`
- **환경 변수**: `REPLAY_ARCHIVE_DIR` (설정 시 우선 사용)

### 최대 리플레이 수
- **기본값**: 300개
- **환경 변수**: `MAX_REPLAYS_FOR_LEARNING` (설정 시 우선 사용)

### 반복 횟수
- **기본값**: 5회
- **코드 수정**: `pro_replay_learning_workflow.py`의 `max_iterations` 변수 수정

---

## ? 개선 프로세스

각 반복마다:

1. **프로게이머 리플레이 학습** → 최신 빌드오더 파라미터 추출
2. **게임 훈련** → 학습된 빌드오더로 게임 실행
3. **비교 분석** → 봇과 프로게이머의 차이점 분석
4. **자동 개선** → 다음 반복에서 개선된 파라미터 적용

이 과정을 반복하여 봇의 빌드오더가 프로게이머 수준에 가까워지도록 개선합니다.

---

## ? 결과 확인

### 학습된 파라미터 확인
```bash
python tools\show_learning_rate.py
```

### 훈련 진행 상황 모니터링
```bash
python tools\monitor_training_progress.py
```

### 비교 리포트 확인
- 위치: `local_training/comparison_reports/comparison_analysis_report.md`
- 내용: 시간 오차, 순서 오류, 자원 효율 분석 결과

---

## ?? 주의사항

1. **리플레이 파일**: 프로게이머 리플레이가 `D:\replays\replays`에 있어야 합니다.
2. **게임 훈련 시간**: 게임 훈련은 가장 오래 걸리는 단계입니다.
3. **디스크 공간**: 리플레이 파일과 학습 데이터가 저장되므로 충분한 디스크 공간이 필요합니다.

---

## ? 기대 효과

- **빌드오더 최적화**: 프로게이머 수준의 빌드오더 타이밍 학습
- **자원 효율 향상**: 프로게이머의 자원 관리 패턴 학습
- **전략 다양화**: 다양한 프로게이머의 전략 학습
- **지속적 개선**: 반복 학습을 통한 지속적 성능 향상

---

**프로게이머 리플레이 학습 및 게임 훈련 적용 워크플로우 준비 완료.**
